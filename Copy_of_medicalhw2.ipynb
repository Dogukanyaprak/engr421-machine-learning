{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDlQ5eiEGyDDfiXRLvdFVT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dogukanyaprak/engr421-machine-learning/blob/main/Copy_of_medicalhw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwbqXpqaacG2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsxcdSwSupX7",
        "outputId": "a54a84ea-55bd-4a7f-d024-3cf4ae74e336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iNFdYV0FEvr",
        "outputId": "e1e11720-ed59-4354-acc6-0593aecb538d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "vH6Wj5ZkFYiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSvN0nc6Fc6O",
        "outputId": "3fdc033e-db58-4ffc-8191-09054dd5e194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AlexNet',\n",
              " 'AlexNet_Weights',\n",
              " 'ConvNeXt',\n",
              " 'ConvNeXt_Base_Weights',\n",
              " 'ConvNeXt_Large_Weights',\n",
              " 'ConvNeXt_Small_Weights',\n",
              " 'ConvNeXt_Tiny_Weights',\n",
              " 'DenseNet',\n",
              " 'DenseNet121_Weights',\n",
              " 'DenseNet161_Weights',\n",
              " 'DenseNet169_Weights',\n",
              " 'DenseNet201_Weights',\n",
              " 'EfficientNet',\n",
              " 'EfficientNet_B0_Weights',\n",
              " 'EfficientNet_B1_Weights',\n",
              " 'EfficientNet_B2_Weights',\n",
              " 'EfficientNet_B3_Weights',\n",
              " 'EfficientNet_B4_Weights',\n",
              " 'EfficientNet_B5_Weights',\n",
              " 'EfficientNet_B6_Weights',\n",
              " 'EfficientNet_B7_Weights',\n",
              " 'EfficientNet_V2_L_Weights',\n",
              " 'EfficientNet_V2_M_Weights',\n",
              " 'EfficientNet_V2_S_Weights',\n",
              " 'GoogLeNet',\n",
              " 'GoogLeNetOutputs',\n",
              " 'GoogLeNet_Weights',\n",
              " 'Inception3',\n",
              " 'InceptionOutputs',\n",
              " 'Inception_V3_Weights',\n",
              " 'MNASNet',\n",
              " 'MNASNet0_5_Weights',\n",
              " 'MNASNet0_75_Weights',\n",
              " 'MNASNet1_0_Weights',\n",
              " 'MNASNet1_3_Weights',\n",
              " 'MaxVit',\n",
              " 'MaxVit_T_Weights',\n",
              " 'MobileNetV2',\n",
              " 'MobileNetV3',\n",
              " 'MobileNet_V2_Weights',\n",
              " 'MobileNet_V3_Large_Weights',\n",
              " 'MobileNet_V3_Small_Weights',\n",
              " 'RegNet',\n",
              " 'RegNet_X_16GF_Weights',\n",
              " 'RegNet_X_1_6GF_Weights',\n",
              " 'RegNet_X_32GF_Weights',\n",
              " 'RegNet_X_3_2GF_Weights',\n",
              " 'RegNet_X_400MF_Weights',\n",
              " 'RegNet_X_800MF_Weights',\n",
              " 'RegNet_X_8GF_Weights',\n",
              " 'RegNet_Y_128GF_Weights',\n",
              " 'RegNet_Y_16GF_Weights',\n",
              " 'RegNet_Y_1_6GF_Weights',\n",
              " 'RegNet_Y_32GF_Weights',\n",
              " 'RegNet_Y_3_2GF_Weights',\n",
              " 'RegNet_Y_400MF_Weights',\n",
              " 'RegNet_Y_800MF_Weights',\n",
              " 'RegNet_Y_8GF_Weights',\n",
              " 'ResNeXt101_32X8D_Weights',\n",
              " 'ResNeXt101_64X4D_Weights',\n",
              " 'ResNeXt50_32X4D_Weights',\n",
              " 'ResNet',\n",
              " 'ResNet101_Weights',\n",
              " 'ResNet152_Weights',\n",
              " 'ResNet18_Weights',\n",
              " 'ResNet34_Weights',\n",
              " 'ResNet50_Weights',\n",
              " 'ShuffleNetV2',\n",
              " 'ShuffleNet_V2_X0_5_Weights',\n",
              " 'ShuffleNet_V2_X1_0_Weights',\n",
              " 'ShuffleNet_V2_X1_5_Weights',\n",
              " 'ShuffleNet_V2_X2_0_Weights',\n",
              " 'SqueezeNet',\n",
              " 'SqueezeNet1_0_Weights',\n",
              " 'SqueezeNet1_1_Weights',\n",
              " 'SwinTransformer',\n",
              " 'Swin_B_Weights',\n",
              " 'Swin_S_Weights',\n",
              " 'Swin_T_Weights',\n",
              " 'Swin_V2_B_Weights',\n",
              " 'Swin_V2_S_Weights',\n",
              " 'Swin_V2_T_Weights',\n",
              " 'VGG',\n",
              " 'VGG11_BN_Weights',\n",
              " 'VGG11_Weights',\n",
              " 'VGG13_BN_Weights',\n",
              " 'VGG13_Weights',\n",
              " 'VGG16_BN_Weights',\n",
              " 'VGG16_Weights',\n",
              " 'VGG19_BN_Weights',\n",
              " 'VGG19_Weights',\n",
              " 'ViT_B_16_Weights',\n",
              " 'ViT_B_32_Weights',\n",
              " 'ViT_H_14_Weights',\n",
              " 'ViT_L_16_Weights',\n",
              " 'ViT_L_32_Weights',\n",
              " 'VisionTransformer',\n",
              " 'Weights',\n",
              " 'WeightsEnum',\n",
              " 'Wide_ResNet101_2_Weights',\n",
              " 'Wide_ResNet50_2_Weights',\n",
              " '_GoogLeNetOutputs',\n",
              " '_InceptionOutputs',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_api',\n",
              " '_meta',\n",
              " '_utils',\n",
              " 'alexnet',\n",
              " 'convnext',\n",
              " 'convnext_base',\n",
              " 'convnext_large',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'densenet',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'detection',\n",
              " 'efficientnet',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_v2_l',\n",
              " 'efficientnet_v2_m',\n",
              " 'efficientnet_v2_s',\n",
              " 'get_model',\n",
              " 'get_model_builder',\n",
              " 'get_model_weights',\n",
              " 'get_weight',\n",
              " 'googlenet',\n",
              " 'inception',\n",
              " 'inception_v3',\n",
              " 'list_models',\n",
              " 'maxvit',\n",
              " 'maxvit_t',\n",
              " 'mnasnet',\n",
              " 'mnasnet0_5',\n",
              " 'mnasnet0_75',\n",
              " 'mnasnet1_0',\n",
              " 'mnasnet1_3',\n",
              " 'mobilenet',\n",
              " 'mobilenet_v2',\n",
              " 'mobilenet_v3_large',\n",
              " 'mobilenet_v3_small',\n",
              " 'mobilenetv2',\n",
              " 'mobilenetv3',\n",
              " 'optical_flow',\n",
              " 'quantization',\n",
              " 'regnet',\n",
              " 'regnet_x_16gf',\n",
              " 'regnet_x_1_6gf',\n",
              " 'regnet_x_32gf',\n",
              " 'regnet_x_3_2gf',\n",
              " 'regnet_x_400mf',\n",
              " 'regnet_x_800mf',\n",
              " 'regnet_x_8gf',\n",
              " 'regnet_y_128gf',\n",
              " 'regnet_y_16gf',\n",
              " 'regnet_y_1_6gf',\n",
              " 'regnet_y_32gf',\n",
              " 'regnet_y_3_2gf',\n",
              " 'regnet_y_400mf',\n",
              " 'regnet_y_800mf',\n",
              " 'regnet_y_8gf',\n",
              " 'resnet',\n",
              " 'resnet101',\n",
              " 'resnet152',\n",
              " 'resnet18',\n",
              " 'resnet34',\n",
              " 'resnet50',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'resnext50_32x4d',\n",
              " 'segmentation',\n",
              " 'shufflenet_v2_x0_5',\n",
              " 'shufflenet_v2_x1_0',\n",
              " 'shufflenet_v2_x1_5',\n",
              " 'shufflenet_v2_x2_0',\n",
              " 'shufflenetv2',\n",
              " 'squeezenet',\n",
              " 'squeezenet1_0',\n",
              " 'squeezenet1_1',\n",
              " 'swin_b',\n",
              " 'swin_s',\n",
              " 'swin_t',\n",
              " 'swin_transformer',\n",
              " 'swin_v2_b',\n",
              " 'swin_v2_s',\n",
              " 'swin_v2_t',\n",
              " 'vgg',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'video',\n",
              " 'vision_transformer',\n",
              " 'vit_b_16',\n",
              " 'vit_b_32',\n",
              " 'vit_h_14',\n",
              " 'vit_l_16',\n",
              " 'vit_l_32',\n",
              " 'wide_resnet101_2',\n",
              " 'wide_resnet50_2']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "\n",
        "model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6z_N2NBSKVj",
        "outputId": "3a6fcedb-6413-4c11-bb74-15b79db5fcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers in the network\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "ExRwevP1IhSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model.classifier[6].in_features  # Accessing the last layer's input features\n",
        "model.classifier[6] = nn.Linear(num_features, 3)"
      ],
      "metadata": {
        "id": "UpF2xEYtIlG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_LOCATION = \"./dataset\""
      ],
      "metadata": {
        "id": "JUp60vrhg-xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "YiWNSoF2mGmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "Kaf-3K7MmRXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "\n",
        "print(os.listdir('/content/gdrive/My Drive'))\n",
        "\n",
        "DATA_LOCATION = '/content/gdrive/My Drive/dataset'\n",
        "\n",
        "print(\"Contents of dataset directory:\", os.listdir(DATA_LOCATION))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu8eJ_LXk_19",
        "outputId": "891334a4-16ad-4ea7-ed30-c9e2f50da97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Getting started.pdf', 'Copy of Human Rights Violation In USA.pptx.gslides', 'Donör KOÇ 2018.xlsx', '02.10.2018 BCA assay SectionA.xlsx', '02.10.2018 BCA assay SectionA.gsheet', 'draft1.docx', 'MBGE 111 Lab experiment 4 İbrahim Batuhan Peltek.docx', 'MBGE 111 Lab experiment 4 İbrahim Batuhan Peltek.gdoc', 'plan.xlsx', 'notesfrompw.docx', 'Bostrom Transhumanist Values.pdf', 'thecellsixthedition.pdf', 'Party Planner (1).numbers', 'Party Planner.numbers', 'keywords for the final fall 2018.docx', 'Lecture 21 - membrane structure_KB.pptx', 'Lecture 22-Intracellular compartments and protein sorting-CAA2.pptx', 'CHEM 200 6 Feb 2019.pdf', 'Note 18 Feb 2019.pdf', 'exercise chap 7-8.gdoc', 'dekont.pdf', 'image (1).jpg', 'image.jpg', 'FZT-FTT ÖZGEÇMİŞ', 'Dekont. (1).pdf', 'Dekont..pdf', 'PNG image.png', 'Simple Budget.numbers', 'MEDI201-intro to molecular biology and genetics-CAA2019.pptx', 'General considerations on bones, joints and muscles 2020.pptx', 'YEAR 2 2019-2020 oryantasyon.pptx', 'Bülent Ahıshalı__Intro to Histology 2019.pptx', 'MED EDU 2019.pptx', 'LecProj1Questions.zip (Unzipped Files)', 'Notability (2)', 'Notability (1)', 'Notability', 'Copy of IMG_9479.HEIC', 'Covid Meta-analysis', 'Copy of Clean Sheet.gdoc', 'Dekont.pdf', 'cv Doğukan YAPRAK copy (1).pdf', 'META 2', 'inventory - Line chart 1.gsheet', 'Database Note 14 Aug 2022.pdf', 'GH010735.MP4', 'GH010738.MP4', 'medi201 - introduction to molecular biology and genetics-CAA (Lecture 1-2).pptx', 'TYAO Analiz.docx', 'ANGEN Tenik Analiz.docx', 'BIMAS Tenik Analiz son.docx', 'cv Doğukan YAPRAK copy.pdf', 'Untitled Diagram (3).drawio', 'Untitled Diagram (2).drawio', 'Untitled SSD Diagram.drawio', 'Untitled Sequence Diagram .drawio', 'kep alp-serhat', 'Untitled Diagram (1).drawio', 'Untitled Diagram.drawio', 'Batch 2.zip (Unzipped Files)', '71741_eertunc19_ps8.gdoc', '0064910_dyaprak17_ps12.gdoc', 'comp 304.zip', 'dataset', 'Untitled0.ipynb']\n",
            "Contents of dataset directory: ['test_labels.txt', 'training_labels.txt', 'test', 'training']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images_folder, labels_file, transform=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.transform = transform\n",
        "        self.labels = []\n",
        "        self.image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg')]\n",
        "\n",
        "        # Read the labels file and store contents in a list\n",
        "        with open(labels_file, 'r') as file:\n",
        "            self.labels = [int(line.strip()) for line in file]\n",
        "\n",
        "        if len(self.labels) != len(self.image_files):\n",
        "            raise ValueError(\"Number of labels and images does not match\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_folder, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "Cipjm0DMs6Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "pYrAIY7-FE6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the training dataset\n",
        "train_dataset = CustomDataset(\n",
        "    images_folder='/content/gdrive/My Drive/dataset/training',\n",
        "    labels_file='/content/gdrive/My Drive/dataset/training_labels.txt',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# Initialize the testing dataset\n",
        "test_dataset = CustomDataset(\n",
        "    images_folder='/content/gdrive/My Drive/dataset/test',\n",
        "    labels_file='/content/gdrive/My Drive/dataset/test_labels.txt',\n",
        "    transform=transform\n",
        ")\n"
      ],
      "metadata": {
        "id": "8Hpq9OJVFGdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# Define the size of the validation set\n",
        "num_train = len(train_dataset)\n",
        "num_valid = int(0.2 * num_train)  # 20% of the training set for validation\n",
        "num_train -= num_valid\n",
        "\n",
        "# Split the dataset\n",
        "train_subset, valid_subset = random_split(train_dataset, [num_train, num_valid])\n",
        "\n",
        "# Define your DataLoaders\n",
        "train_loader = DataLoader(train_subset, batch_size=4, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_subset, batch_size=4, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\n"
      ],
      "metadata": {
        "id": "FziZIQV2HFrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.classifier[6].parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "bH6TRpc2HJtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {\n",
        "    'train': train_loader,\n",
        "    'valid': valid_loader,\n",
        "    'test': test_loader\n",
        "}"
      ],
      "metadata": {
        "id": "2ZpsfnpxJwQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['train', 'valid']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Adjust labels here if they are 1-indexed instead of 0-indexed\n",
        "            labels = labels - 1\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        if phase == 'valid' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "print('Best val Acc: {:4f}'.format(best_acc))\n",
        "model.load_state_dict(best_model_wts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIewY1toJSuJ",
        "outputId": "325e35e2-5c9f-4a0d-eeb9-28119f010954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "train Loss: 1.7625 Acc: 0.5705\n",
            "valid Loss: 1.4929 Acc: 0.7027\n",
            "Epoch 2/5\n",
            "----------\n",
            "train Loss: 1.1294 Acc: 0.7181\n",
            "valid Loss: 0.6151 Acc: 0.8108\n",
            "Epoch 3/5\n",
            "----------\n",
            "train Loss: 0.3264 Acc: 0.8993\n",
            "valid Loss: 0.8027 Acc: 0.8378\n",
            "Epoch 4/5\n",
            "----------\n",
            "train Loss: 0.6293 Acc: 0.8121\n",
            "valid Loss: 0.9210 Acc: 0.7568\n",
            "Epoch 5/5\n",
            "----------\n",
            "train Loss: 0.6249 Acc: 0.8456\n",
            "valid Loss: 0.6568 Acc: 0.8378\n",
            "Best val Acc: 0.837838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}